## 1.Broker丢失消息

Broker丢失消息是由于Kafka本身的原因造成的，kafka为了得到更高的性能和吞吐量，将数据异步批量的存储在磁盘中。消息的刷盘过程，为了提高性能，减少刷盘次数，kafka采用了批量刷盘的做法。即，按照一定的消息量，和时间间隔进行刷盘。

这种机制也是由于linux操作系统决定的。将数据存储到linux操作系统种，会先存储到页缓存（Page cache）中，按照时间或者其他条件进行刷盘（从page cache到file），或者通过fsync命令强制刷盘。数据在page cache中时，如果系统挂掉，数据会丢失。

![img](file:///Users/xuebo/Documents/note/kafka/broker%E4%B8%A2%E5%A4%B1%E6%B6%88%E6%81%AF.png?lastModify=1644034083)

上图简述了broker写数据以及同步的一个过程。broker写数据只写到PageCache中，而pageCache位于内存。这部分数据在断电后是会丢失的。pageCache的数据通过linux的flusher程序进行刷盘。刷盘触发条件有三：

- 主动调用sync或fsync函数
- 可用内存低于阀值
- dirty data时间达到阀值。dirty是pagecache的一个标识位，当有数据写入到pageCache时，pagecache被标注为dirty，数据刷盘以后，dirty标志清除。

Broker配置刷盘机制，是通过调用fsync函数接管了刷盘动作。从单个Broker来看，pageCache的数据会丢失。

为了解决该问题，kafka通过producer和broker协同处理单个broker丢失参数的情况。一旦producer发现broker消息丢失，即可自动进行retry。除非retry次数超过阀值（可配置），消息才会丢失。此时需要生产者客户端手动处理该情况。那么producer是如何检测到数据丢失的呢？是通过ack机制，类似于http的三次握手的方式。

Kafka 通过配置 request.required.acks 属性来确认 Producer 的消息：

- 0：表示不进行消息接收是否成功的确认；不能保证消息是否发送成功，生成环境基本不会用。
- 1：默认值，表示当 Leader 接收成功时确认；只要 Leader 存活就可以保证不丢失，保证了吞吐量。所以默认的 producer 级别是 at least once。
- -1/all：保证 leader 和 follower 不丢，但是如果网络拥塞，没有收到 ACK，会有重复发的问题。

如果 acks 配置为 0，发生网络抖动消息丢了，生产者不校验 ACK 自然就不知道丢了。

如果 acks 配置为 1 保证 leader 不丢，但是如果 leader 挂了，恰好选了一个没有 ACK 的 follower，那也丢了。

如果 acks 配置为 all 保证 leader 和 follower 不丢，但是如果网络拥塞，没有收到 ACK，会有重复发的问题。

####重复发送问题产生原因

producer等待broker的ack，partition的 leader和 follower全部落盘成功后才返回ack。但是如果在 follower同步完成后，broker发送ack 之前，leader 发生故障，那么会造成数据重复。
例如：follower刚刚同步完成，此时leader还没有发送ack，leader挂了之后，重新选出新的leader，而producer没有收到ack，于是重发消息，此时新leader又收到了相同的消息，产生数据重复的问题。	

####故障数据同步

![在这里插入图片描述](/Users/xuebo/Documents/note/kafka/故障数据同步.png)

1、follower发生故障：
follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log 文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即 follower追上 leader之后，就可以重新加入ISR了。

2、leader发生故障：
leader 发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性,其余的follower会先将各自的 log文件高于HW的部分截掉,然后从新的leader同步数据。

##2.生产者丢失消息

####1.1生产者发送消息的一般流程

1. 生产者是与 leader 直接交互，所以先从集群获取 topic 对应分区的 leader 元数据；(老版本从zk获取)
2. 获取到 leader 分区元数据后直接将消息发给过去；
3. Kafka Broker 对应的 leader 分区收到消息后写入文件持久化；
4. Follower 拉取 Leader 消息与 Leader 的数据保持一致；
5. Follower 消息拉取完毕需要给 Leader 回复 ACK 确认消息；
6. Kafka Leader 和 Follower 分区同步完，Leader 分区会给生产者回复 ACK 确认消息。

![img](/Users/xuebo/Documents/note/kafka/生产者发送消息过程.png)

生产者采用 push 模式将数据发布到 broker，每条消息追加到分区中，顺序写入磁盘。消息写入 Leader 后，Follower 是主动与 Leader 进行同步。

#### 1.2生产者丢失消息原因及解决方案

##### 1.2.1 producer的buffer导致

Kafka 消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过 producer.type 属性进行配置。

为了提升效率，减少IO，producer在发送数据时可以将多个请求进行合并后发送。被合并的请求咋发送一线缓存在本地buffer中。producer可以将请求打包成“块”或者按照时间间隔，将buffer中的数据发出。通过buffer我们可以将生产者改造为异步的方式，而这可以提升我们的发送效率。

但是，buffer中的数据就是危险的。在正常情况下，客户端的异步调用可以通过callback来处理消息发送失败或者超时的情况，但是，一旦producer被非法的停止了，那么buffer中的数据将丢失，broker将无法收到该部分数据。又或者，当Producer客户端内存不够时，如果采取的策略是丢弃消息（另一种策略是block阻塞），消息也会被丢失。抑或，消息产生（异步产生）过快，导致挂起线程过多，内存不足，导致程序崩溃，消息丢失。

![preview](/Users/xuebo/Documents/note/kafka/生产者buffer导致丢消息原理.png)

![preview](/Users/xuebo/Documents/note/kafka/生产者buffer导致丢失消息原理2.png)

根据上图，可以想到几个解决的思路：

- 异步发送消息改为同步发送消息。或者service产生消息时，使用阻塞的线程池，并且线程数有一定上限。整体思路是控制消息产生速度。
- 扩大Buffer的容量配置。这种方式可以缓解该情况的出现，但不能杜绝。
- service不直接将消息发送到buffer（内存），而是将消息写到本地的磁盘中（数据库或者文件），由另一个（或少量）生产线程进行消息发送。相当于是在buffer和service之间又加了一层空间更加富裕的缓冲层。

##3.消费者丢失消息

老版本offset维护在zk上，新版本维护在broker中的特殊topic：consumer_offset

###单线程消费

Consumer消费消息有下面几个步骤：

- 接收消息
- 处理消息
- 反馈“处理完毕”（commited）

Consumer的消费方式主要分为两种：

- 自动提交offset，Automatic Offset Committing
- 手动提交offset，Manual Offset Control

Consumer自动提交的机制是根据一定的时间间隔，将收到的消息进行commit。commit过程和消费消息的过程是异步的。也就是说，可能存在消费过程未成功（比如抛出异常），commit消息已经提交了。此时消息就丢失了。

### 多线程消费

